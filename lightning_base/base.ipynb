{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68664161-6341-410b-9533-421707d06d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sklearn\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.loggers.base import LightningLoggerBase\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional, List, Dict, Any, Callable\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pl.utilities.seed.seed_everything(42)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece627e-266b-407b-85c8-caead7e3e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit_transform(data)\n",
    "\n",
    "def standarize(data):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240d5d9-b20d-4dac-98f0-47b06b0032d7",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897f617-83d6-443e-98b9-ddd62bedc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str, test_size: float = 0.3, val_size: float = 0.1, train_batch_size: int = 64, val_batch_size: int = 64, transforms: List[Callable] = [], no_batch: bool = False):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.test_size = test_size\n",
    "        self.val_size = val_size\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.val_batch_size = val_batch_size\n",
    "        self.no_batch = no_batch\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        self.full_data = pd.read_csv(self.data_dir)\n",
    "        X = self.full_data.values[:, :-1]\n",
    "        y = self.full_data.values[:, -1]\n",
    "        for transform in self.transforms:\n",
    "            X = transform(X)\n",
    "        self.transformed_data = X\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, stratify=y)\n",
    "        X_train = torch.tensor(X_train).float()\n",
    "        X_test = torch.tensor(X_test).float()\n",
    "        y_train = torch.tensor(y_train).long()\n",
    "        y_test = torch.tensor(y_test).long()\n",
    "        \n",
    "        self.train_data = (X_train, y_train)\n",
    "        self.test_data = (X_test, y_test)\n",
    "    \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            X_train, y_train = self.train_data\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=self.val_size, stratify=y_train)\n",
    "            self.train_data = []\n",
    "            self.val_data = []\n",
    "            for x, y in zip(X_train, y_train):\n",
    "                self.train_data.append((x, y))\n",
    "                \n",
    "            for x, y in zip(X_val, y_val):\n",
    "                self.val_data.append((x, y))\n",
    "            \n",
    "            if self.no_batch:\n",
    "                self.train_batch_size = len(self.train_data)\n",
    "                self.val_batch_size = len(self.val_data)\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            X_test, y_test = self.test_data\n",
    "            self.test_data = []\n",
    "            for x, y in zip(X_test, y_test):\n",
    "                self.test_data.append((x, y))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, self.train_batch_size, shuffle=True, num_workers=1, pin_memory=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data, self.val_batch_size, shuffle=False, num_workers=1, pin_memory=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, shuffle=False, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5501693-3006-47bb-b8b6-cf2c53cc742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize data\n",
    "datamodule = DataModule('', no_batch=True, transforms=[normalize])\n",
    "datamodule.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d74ca-5dda-4149-b40c-a52015c67dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.full_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22daf67-711d-4138-a463-d216f4290fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b63d6cb-b647-4330-941e-280972d5059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.full_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed7253d-9f11-4feb-920f-89179e68ce98",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d519ce4-0be9-4874-8726-77a31c5673ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(data, x, y, figsize=(13, 13), bins=15):\n",
    "    fig, ax = plt.subplots(x, y, figsize=figsize)\n",
    "    for i in range(data.transformed_data.shape[1]):\n",
    "        ax[int(i / y), i % y].hist(data.transformed_data[:, i], bins=bins)\n",
    "        ax[int(i / y), i % y].set_title(data.full_data.columns[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337bfd15-2b02-4c7f-b1d3-cb29c8fc9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(datamodule, 2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484dca68-0263-4106-8aeb-b1677a77d652",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeab466-3e37-4d0b-8680-38a2f12e1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self, model, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)\n",
    "        \n",
    "    def shared_step(self, x, y):\n",
    "        pred = self(x)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(pred, y)\n",
    "        return pred, loss\n",
    "        \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        pred, loss = self.shared_step(x, y)\n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        return {'loss': loss, 'train_score': (predicted, y)}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss = [output['loss'] for output in outputs]\n",
    "        loss_nd = np.double(loss[-1].detach().cpu().numpy())\n",
    "        \n",
    "        results = [x['train_score'] for x in outputs]\n",
    "        preds = []\n",
    "        y = []\n",
    "        for predicted, y_data in results:\n",
    "            predicted = predicted.detach().cpu().numpy()\n",
    "            y_data = y_data.detach().cpu().numpy()\n",
    "            preds.extend(predicted)\n",
    "            y.extend(y_data)\n",
    "        f1 = f1_score(y, preds)\n",
    "        self.log('loss', loss_nd, logger=True)\n",
    "        self.log('train_f1', f1, prog_bar=True, logger=True)\n",
    "    \n",
    "    def validation_step(self, val_batch, val_batch_idx):\n",
    "        x, y = val_batch\n",
    "        pred, loss = self.shared_step(x, y)\n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        return {'val_loss': loss, 'val_score': (predicted, y)}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        results = [x['val_score'] for x in outputs]\n",
    "        preds = []\n",
    "        y = []\n",
    "        for predicted, y_data in results:\n",
    "            predicted = predicted.detach().cpu().numpy()\n",
    "            y_data = y_data.detach().cpu().numpy()\n",
    "            preds.extend(predicted)\n",
    "            y.extend(y_data)\n",
    "        f1 = f1_score(y, preds)\n",
    "        self.log('val_f1', f1, prog_bar=True, logger=True)\n",
    "        \n",
    "    def test_step(self, test_batch, test_batch_idx):\n",
    "        x, y = test_batch\n",
    "        pred, loss = self.shared_step(x, y)\n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        return {'test_loss': loss, 'test_score': (predicted, y)}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        results = [x['test_score'] for x in outputs]\n",
    "        preds = []\n",
    "        y = []\n",
    "        for predicted, y_data in results:\n",
    "            predicted = predicted.detach().cpu().numpy()\n",
    "            y_data = y_data.detach().cpu().numpy()\n",
    "            preds.extend(predicted)\n",
    "            y.extend(y_data)\n",
    "        acc = accuracy_score(y, preds)\n",
    "        f1 = f1_score(y, preds)\n",
    "        self.log('accuracy', acc, prog_bar=True, logger=True)\n",
    "        self.log('f1', f1, prog_bar=True, logger=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6dc68-5871-4e16-86aa-016b69ac7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.name = ''\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self._nn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4174bb-4ab0-4337-a884-70318c6dfe4a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f13c7d-fdf1-4425-9260-fce8c3e6a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(elem: Any, count: int, step: Any):\n",
    "    current = elem\n",
    "    output = []\n",
    "    for _ in range(count):\n",
    "        output.append(current)\n",
    "        current += step\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850dcb23-5192-4ff9-80dc-b1ae430c0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, models: List[pl.LightningModule], version: str, trainer_params: Dict[str, Any] = {}, logger: LightningLoggerBase = MLFlowLogger, logger_params: Dict[str, Any] = {}, \n",
    "                 callbacks: List[Callback] = [], callbacks_params: List[Dict[str, Any]] = [{}]):\n",
    "        self.models = models\n",
    "        self.classifiers = [Classifier(model) for model in models]\n",
    "        self.version = version\n",
    "        self.paths = ['model/' + version + model.name for model in models]\n",
    "        self.loggers = [logger(**logger_params) for _ in models]\n",
    "        self.trainer_params = trainer_params\n",
    "        self.callbacks = []\n",
    "        for _ in models:\n",
    "            self.callbacks.append([callback(**params) for callback, params in zip(callbacks, callbacks_params)])\n",
    "    \n",
    "    def train(self, min_lr: float, datamodule: pl.LightningDataModule, transforms: List[Callable] = [], find_lr: bool = True, verbose: bool = False, no_batch: bool = False):\n",
    "        for path, classifier, logger in zip(self.paths, self.classifiers, self.loggers):\n",
    "            self.trainer = pl.Trainer(logger=logger, **self.trainer_params)\n",
    "            if find_lr:\n",
    "                lr_finder = self.trainer.tuner.lr_find(classifier, min_lr=min_lr, datamodule=datamodule(no_batch=no_batch, transforms=transforms), early_stop_threshold=None)\n",
    "                classifier.lr = lr_finder.suggestion()\n",
    "            else:\n",
    "                classifier.lr = min_lr\n",
    "\n",
    "            if verbose and find_lr:\n",
    "                print(f'Best lr: {classifier.lr}')\n",
    "\n",
    "            self.trainer.fit(classifier, datamodule(no_batch=no_batch, transforms=transforms))\n",
    "            self.trainer.save_checkpoint(path)\n",
    "    \n",
    "    def test(self, datamodule: pl.LightningDataModule, transforms: List[Callable], no_batch: bool = False):\n",
    "        for path, model, logger in zip(self.paths, self.models, self.loggers):\n",
    "            self.trainer = pl.Trainer(logger=logger, **self.trainer_params)\n",
    "            classifier = Classifier.load_from_checkpoint(path, model=model)\n",
    "            self.trainer.test(classifier, datamodule=datamodule(no_batch=no_batch, transforms=transforms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d74ac-0ea4-4769-b454-c74505c93ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSearch:\n",
    "    def __init__(self, linear_params, linear_params_count):\n",
    "        self.linear_params = linear_params\n",
    "        self.linear_params_count = linear_params_count\n",
    "    \n",
    "    def search(self, models: List[pl.LightningModule], in_size: int, out_size: int, datamodule: pl.LightningDataModule, versions: List[str], min_lr: float = 1e-03, transforms: List[Callable] = [], \n",
    "               find_lr=False, verbose=False, callbacks: List[Callback] = [], callbacks_params: List[Dict[str, Any]] = [{}]):\n",
    "        for i in range(self.linear_params_count):\n",
    "            obj_models = [model(in_size, out_size) for model in models]\n",
    "            params = {}\n",
    "            for key in self.linear_params.keys():\n",
    "                params[key] = self.linear_params[key][i]\n",
    "            if verbose:\n",
    "                print(params)\n",
    "            evaluator = Evaluator(obj_models, versions[i], params, callbacks=callbacks, callbacks_params=callbacks_params)\n",
    "            evaluator.train(min_lr, datamodule, transforms, find_lr=find_lr, verbose=verbose)\n",
    "            evaluator.test(datamodule, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a58a95b-d725-4fd1-ab2b-c3f397f8a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [] #Objects\n",
    "min_lr = 1e-03\n",
    "in_size = 0\n",
    "out_size = 0\n",
    "datamodule = DataModule\n",
    "transforms = [normalize]\n",
    "callbacks = [] # List of callback class names\n",
    "callbacks_params = [{}] # List of corresponding parameters\n",
    "linear_params_count = 6\n",
    "linear_params = {\n",
    "    'gpus': generate(1, params_count, 0),\n",
    "    'max_epochs': [20, 30, 40, 50, 75, 100],\n",
    "    'gradient_clip_val': generate(0.5, params_count, 0.),\n",
    "    'stochastic_weight_avg': generate(True, params_count, False),\n",
    "    'amp_level': generate('O3', params_count, ''),\n",
    "    'precision': generate(16, params_count, 0)\n",
    "}\n",
    "versions = [str(max_epoch) + 'epoch_' for max_epoch in params['max_epochs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243800c-d684-4fa8-a005-3833fff55255",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_search = LinearSearch(linear_params, linear_params_count)\n",
    "linear_search.search(models, in_size, out_size, datamodule, versions, min_lr, transforms, False, False, callbacks, callbacks_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d788588-bd65-4ee4-96c7-b9045d056e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
